{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificador Marvel.\n",
        "¿Alguna vez has deseado saber el nombre de tus personajes favoritos de Marvel pero tienes una pésima memoria? Ya no vuelvas a pasar por momentos así de vergonzosos, pues el **Clasificador Marvel** ha llegado a salvar el día.  \n",
        "\n",
        "Patrocinado por:\n",
        "- Azure Cloud.\n",
        "- Azure Cognitive Services: Custom Vision.\n",
        "- Innovacción Microsoft.\n",
        "\n",
        "## Ejecución.\n",
        "Es muy sencillo de usar siempre y cuando sepas correr Jupyter Notebooks, o puedas correr el siguiente código de Python.  \n",
        "\n",
        "El primer paso es instalar el cliente de Azure, con el siguiente comando:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-cognitiveservices-vision-customvision"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego importamos algunas bibliotecas que nos servirán para conectarnos con Custom Vision, desplegar imágenes, entre otras cosas:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from msrest.authentication import ApiKeyCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614904216001
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego vamos a preparar algunas variables que necesitamos para ejecutar el código.  \n",
        "\n",
        "Las variables `project_id`, `cv_key`, `cv_endpoint` y `model_name` lo obtenemos tras entrenar nuestro modelo de Custom Vision."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up\n",
        "project_id = '5bfbfe4c-1feb-4d03-981f-6a5609fb964d'\n",
        "cv_key = '1efbfa4470614f0b94e5b97f135c8363'\n",
        "cv_endpoint = 'https://machinelearningwee-prediction.cognitiveservices.azure.com/'\n",
        "model_name = 'Iteration1'\n",
        "\n",
        "directory = 'data'\n",
        "images = os.listdir(directory)\n",
        "\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614904216185
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con lo anterior listo, ya podemos comenzar a clasificar. De esto se encarga el cliente de Custom Vision, sólo debemos indicarle la imagen a clasificar."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Classify\n",
        "classification_results = []\n",
        "\n",
        "for i in range(len(images)):\n",
        "    print(\"Classifying image {} out of {}\".format(i+1, len(images)))\n",
        "    image_data = open(os.path.join(directory, images[i]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_data.read())\n",
        "    classification_results.append(classification)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614904258611
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo anterior puede tomar un par de segundos en ejecutarse.  \n",
        "\n",
        "El siguiente código nos sirve para deplegar los resultados:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(32, 32))\n",
        "\n",
        "for i in range(len(images)):\n",
        "    prediction = classification_results[i].predictions[0].tag_name\n",
        "    img = Image.open(os.path.join(directory, images[i]))\n",
        "\n",
        "    a=fig.add_subplot(len(images)/4, 4,i+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614904311698
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En nuestro experimento, obtuvimos 37 de 40 imágenes correctas, un 92.5%.  \n",
        "\n",
        "Pero no nos detuvimos ahí...\n",
        "\n",
        "## Logic Apps\n",
        "Ya vimos que podemos consumir fácilmente el modelo de predicción. Pero a veces queremos usar esa información para mejorar nuestro modelo a futuro.  \n",
        "\n",
        "Una idea que se nos ocurrió es mantener un registro de las imágenes que se clasifican y los resultados.  \n",
        "\n",
        "Con ese propósito utilizamos un flujo del trabajo como el siguiente, todo en la nube de Azure:\n",
        "![Imagen](/assets/IA-Reto3.jpeg)\n",
        "\n",
        "Esto mismo se puede extender, de manera que un script, app, sitio web, etc, suba las imágenes al Blob Storage. Ya con la información almacenada en la nube, las posibilidades son ilimitadas y depende de nosotros los desarrolladores generar las ideas.\n",
        "\n",
        "Además, consideramos que esta misma configuración se puede extender a otros proyectos, con otros modelos de Custom Vision."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}